{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('.venv')",
   "metadata": {
    "interpreter": {
     "hash": "38efbb7de01d3aab19d9ed5849c98dfab9ed16c9875c18769b7a1b3387fe98cf"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, None, 64)          64000     \n_________________________________________________________________\nlstm (LSTM)                  (None, 128)               98816     \n_________________________________________________________________\ndense (Dense)                (None, 10)                1290      \n=================================================================\nTotal params: 164,106\nTrainable params: 164,106\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Add an Embedding layer expecting input vocab of size 1000, and\n",
    "# output embedding dimension of size 64.\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model.add(layers.LSTM(128))\n",
    "\n",
    "# Add a Dense layer with 10 units.\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, None, 64)          64000     \n_________________________________________________________________\ngru (GRU)                    (None, None, 256)         247296    \n_________________________________________________________________\nsimple_rnn (SimpleRNN)       (None, 128)               49280     \n_________________________________________________________________\ndense_1 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 361,866\nTrainable params: 361,866\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Embedding(input_dim=1000, output_dim=64))\n",
    "\n",
    "# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n",
    "model.add(layers.GRU(256, return_sequences=True))\n",
    "\n",
    "# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n",
    "model.add(layers.SimpleRNN(128))\n",
    "\n",
    "model.add(layers.Dense(10))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(20, 14)\n"
     ]
    }
   ],
   "source": [
    "paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n",
    "\n",
    "lstm_layer = layers.LSTM(64, stateful=True)\n",
    "output = lstm_layer(paragraph1)\n",
    "output = lstm_layer(paragraph2)\n",
    "output = lstm_layer(paragraph3)\n",
    "print(output.shape)\n",
    "\n",
    "# reset_states() will reset the cached state to the original initial_state.\n",
    "# If no initial_state was provided, zero-states will be used by default.\n",
    "lstm_layer.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(60000,)\n(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "sample, sample_label = x_train[0], y_train[0]\n",
    "print(y_train.shape)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 \n",
    "input_dim = 28 \n",
    "units = 64 \n",
    "output_size = 10 \n",
    "\n",
    "def build_model(allow_cudnn_kernel=True):\n",
    "    if allow_cudnn_kernel:\n",
    "        lstm_layer= keras.layers.LSTM(units,input_shape=(None,input_dim))\n",
    "    else:\n",
    "        lstm_layer = keras.layers.RNN(\n",
    "            keras.layers.LSTMCell(units), input_shape=(None, input_dim)\n",
    "        )\n",
    "    model = keras.models.Sequential(\n",
    "        [\n",
    "            lstm_layer,\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dense(output_size),\n",
    "        ]\n",
    "    )\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/4\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.6979 - accuracy: 0.7754 - val_loss: 0.1173 - val_accuracy: 0.9629\n",
      "Epoch 2/4\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.1167 - accuracy: 0.9637 - val_loss: 0.1182 - val_accuracy: 0.9655\n",
      "Epoch 3/4\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0790 - accuracy: 0.9757 - val_loss: 0.0674 - val_accuracy: 0.9787\n",
      "Epoch 4/4\n",
      "938/938 [==============================] - 6s 7ms/step - loss: 0.0662 - accuracy: 0.9785 - val_loss: 0.0545 - val_accuracy: 0.9824\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f437652aeb0>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "model = build_model(allow_cudnn_kernel=True)\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.fit(\n",
    "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=4\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as scs\n",
    "import re\n",
    "from numpy import genfromtxt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, Conv2D,LSTM, BatchNormalization, MaxPooling1D, MaxPooling2D,Reshape\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\nTest data shape: (443, 22, 1000)\nTraining/Valid target shape: (2115,)\nTest target shape: (443,)\nPerson train/valid shape: (2115, 1)\nPerson test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "## Loading the dataset\n",
    "\n",
    "## Loading the numpy arrays\n",
    "\n",
    "X_test = np.load(\"../data/X_test.npy\")\n",
    "y_test = np.load(\"../data/y_test.npy\")\n",
    "person_train_valid = np.load(\"../data/person_train_valid.npy\")\n",
    "X_train_valid = np.load(\"../data/X_train_valid.npy\")\n",
    "y_train_valid = np.load(\"../data/y_train_valid.npy\")\n",
    "person_test = np.load(\"../data/person_test.npy\")\n",
    "\n",
    "## Adjusting the labels so that \n",
    "\n",
    "# Cue onset left - 0\n",
    "# Cue onset right - 1\n",
    "# Cue onset foot - 2\n",
    "# Cue onset tongue - 3\n",
    "\n",
    "y_train_valid -= 769\n",
    "y_test -= 769\n",
    "\n",
    "\n",
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(X,y,sub_sample,average,noise):\n",
    "    \n",
    "    total_X = None\n",
    "    total_y = None\n",
    "    \n",
    "    # Trimming the data\n",
    "    X = X[:,:,0:500]\n",
    "    \n",
    "    # Maxpooling the data\n",
    "    X_max = np.max(X.reshape(X.shape[0], X.shape[1], -1, sub_sample), axis=3)\n",
    "    \n",
    "    total_X = X_max\n",
    "    total_y = y\n",
    "    \n",
    "    # Averaging + noise\n",
    "    X_average = np.mean(X.reshape(X.shape[0], X.shape[1], -1, average),axis=3)\n",
    "    X_average = X_average + np.random.normal(0.0, 0.5, X_average.shape)\n",
    "    \n",
    "    total_X = np.vstack((total_X, X_average))\n",
    "    total_y = np.hstack((total_y, y))\n",
    "    \n",
    "    # Subsampling\n",
    "    \n",
    "    for i in range(sub_sample):\n",
    "        \n",
    "        X_subsample = X[:, :, i::sub_sample] + \\\n",
    "                            (np.random.normal(0.0, 0.5, X[:, :,i::sub_sample].shape) if noise else 0.0)\n",
    "            \n",
    "        total_X = np.vstack((total_X, X_subsample))\n",
    "        total_y = np.hstack((total_y, y))\n",
    "        \n",
    "        \n",
    "    return total_X,total_y\n",
    "\n",
    "\n",
    "X_train_valid_prep,y_train_valid_prep = data_prep(X_train_valid,y_train_valid,2,2,True)\n",
    "X_test_prep,y_test_prep = data_prep(X_test,y_test,2,2,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_valid = np.random.choice(8460, 1500, replace=False)\n",
    "ind_train = np.array(list(set(range(8460)).difference(set(ind_valid))))\n",
    "(x_train, x_valid) = X_train_valid_prep[ind_train], X_train_valid_prep[ind_valid] \n",
    "(y_train, y_valid) = y_train_valid_prep[ind_train], y_train_valid_prep[ind_valid]\n",
    "\n",
    "y_train = to_categorical(y_train, 4)\n",
    "y_valid = to_categorical(y_valid, 4)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], x_valid.shape[1], x_train.shape[2], 1)\n",
    "\n",
    "x_train = np.swapaxes(x_train, 1,3)\n",
    "x_train = np.swapaxes(x_train, 1,2)\n",
    "x_valid = np.swapaxes(x_valid, 1,3)\n",
    "x_valid = np.swapaxes(x_valid, 1,2)\n",
    "\n",
    "x_test = X_test_prep.reshape(X_test_prep.shape[0], X_test_prep.shape[1], X_test_prep.shape[2], 1)\n",
    "x_test = np.swapaxes(x_test, 1,3)\n",
    "x_test = np.swapaxes(x_test, 1,2)\n",
    "y_test = to_categorical(y_test_prep, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 250, 1, 25)        5525      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 84, 1, 25)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 84, 1, 25)         100       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 84, 1, 25)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 84, 1, 50)         12550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 28, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 1, 50)         200       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 28, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 1, 100)        50100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 10, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 1, 200)        200200    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 1, 200)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 4, 1, 200)         800       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 1, 200)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 3204      \n",
      "=================================================================\n",
      "Total params: 273,079\n",
      "Trainable params: 272,329\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "109/109 [==============================] - 2s 13ms/step - loss: 2.1924 - accuracy: 0.2980 - val_loss: 1.3270 - val_accuracy: 0.3980\n",
      "Epoch 2/50\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.5794 - accuracy: 0.3704 - val_loss: 1.1660 - val_accuracy: 0.4967\n",
      "Epoch 3/50\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.3425 - accuracy: 0.4447 - val_loss: 1.1596 - val_accuracy: 0.4640\n",
      "Epoch 4/50\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.2357 - accuracy: 0.4801 - val_loss: 1.1683 - val_accuracy: 0.4727\n",
      "Epoch 5/50\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.1333 - accuracy: 0.5197 - val_loss: 1.0794 - val_accuracy: 0.5480\n",
      "Epoch 6/50\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.0522 - accuracy: 0.5593 - val_loss: 1.0136 - val_accuracy: 0.5553\n",
      "Epoch 7/50\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 1.0136 - accuracy: 0.5845 - val_loss: 0.9815 - val_accuracy: 0.5940\n",
      "Epoch 8/50\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.9715 - accuracy: 0.6059 - val_loss: 0.8980 - val_accuracy: 0.6233\n",
      "Epoch 9/50\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.9231 - accuracy: 0.6214 - val_loss: 0.8435 - val_accuracy: 0.6747\n",
      "Epoch 10/50\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.9090 - accuracy: 0.6289 - val_loss: 0.8986 - val_accuracy: 0.6320\n",
      "Epoch 11/50\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.8542 - accuracy: 0.6605 - val_loss: 0.7571 - val_accuracy: 0.7273\n",
      "Epoch 12/50\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.8530 - accuracy: 0.6573 - val_loss: 0.8170 - val_accuracy: 0.6667\n",
      "Epoch 13/50\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.8011 - accuracy: 0.6813 - val_loss: 0.7218 - val_accuracy: 0.7153\n",
      "Epoch 14/50\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.7821 - accuracy: 0.6817 - val_loss: 0.6298 - val_accuracy: 0.7653\n",
      "Epoch 15/50\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.7248 - accuracy: 0.7119 - val_loss: 0.5878 - val_accuracy: 0.7813\n",
      "Epoch 16/50\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.7162 - accuracy: 0.7153 - val_loss: 0.6082 - val_accuracy: 0.7660\n",
      "Epoch 17/50\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.7342 - accuracy: 0.7087 - val_loss: 0.5495 - val_accuracy: 0.8027\n",
      "Epoch 18/50\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.6900 - accuracy: 0.7239 - val_loss: 0.5569 - val_accuracy: 0.7833\n",
      "Epoch 19/50\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.6622 - accuracy: 0.7359 - val_loss: 0.5944 - val_accuracy: 0.7607\n",
      "Epoch 20/50\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.6714 - accuracy: 0.7349 - val_loss: 0.5265 - val_accuracy: 0.8060\n",
      "Epoch 21/50\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.6418 - accuracy: 0.7512 - val_loss: 0.4736 - val_accuracy: 0.8320\n",
      "Epoch 22/50\n",
      "109/109 [==============================] - 1s 12ms/step - loss: 0.6169 - accuracy: 0.7564 - val_loss: 0.4202 - val_accuracy: 0.8560\n",
      "Epoch 23/50\n",
      "109/109 [==============================] - 1s 13ms/step - loss: 0.5866 - accuracy: 0.7715 - val_loss: 0.4328 - val_accuracy: 0.8453\n",
      "Epoch 24/50\n",
      " 40/109 [==========>...................] - ETA: 0s - loss: 0.5635 - accuracy: 0.7866"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f250df1fdecc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;31m# Training and validating the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m cnn_results = cnn_model.fit(x_train,\n\u001b[0m\u001b[1;32m     52\u001b[0m              \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "dropout = 0.5\n",
    "learning_rate = 1e-3\n",
    "epochs = 50\n",
    "\n",
    "#Building the model\n",
    "\n",
    "cnn_model = Sequential()\n",
    "\n",
    "# First block of conv.\n",
    "cnn_model.add(Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='elu', input_shape=(250,1,22)))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(Dropout(dropout))\n",
    "\n",
    "# Second block of conv.\n",
    "cnn_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(Dropout(dropout))\n",
    "\n",
    "# Third block of conv.\n",
    "cnn_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(Dropout(dropout))\n",
    "\n",
    "# Fourth block of conv.\n",
    "cnn_model.add(Conv2D(filters=200, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "cnn_model.add(BatchNormalization())\n",
    "cnn_model.add(Dropout(dropout))\n",
    "\n",
    "# FC layer\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Defining the optimizer\n",
    "optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "# Compiling the model\n",
    "cnn_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Printing the model summary\n",
    "cnn_model.summary()\n",
    "\n",
    "# Training and validating the model\n",
    "\n",
    "cnn_results = cnn_model.fit(x_train,\n",
    "             y_train,\n",
    "             batch_size=64,\n",
    "             epochs=epochs,\n",
    "             validation_data=(x_valid, y_valid), verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 250, 1, 25)        5525      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 84, 1, 25)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 84, 1, 25)         100       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 84, 1, 25)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 84, 1, 50)         12550     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 28, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 28, 1, 50)         200       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 28, 1, 50)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 1, 100)        50100     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 10, 1, 100)        400       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 10, 1, 100)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                50050     \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 50, 1)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10)                480       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 44        \n",
      "=================================================================\n",
      "Total params: 119,449\n",
      "Trainable params: 119,099\n",
      "Non-trainable params: 350\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "109/109 [==============================] - 4s 27ms/step - loss: 1.3861 - accuracy: 0.2713 - val_loss: 1.3600 - val_accuracy: 0.3333\n",
      "Epoch 2/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 1.3540 - accuracy: 0.3303 - val_loss: 1.2736 - val_accuracy: 0.4020\n",
      "Epoch 3/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 1.2862 - accuracy: 0.3980 - val_loss: 1.1737 - val_accuracy: 0.4527\n",
      "Epoch 4/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 1.2290 - accuracy: 0.4319 - val_loss: 1.1299 - val_accuracy: 0.5020\n",
      "Epoch 5/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 1.1725 - accuracy: 0.4708 - val_loss: 1.1112 - val_accuracy: 0.5067\n",
      "Epoch 6/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 1.1374 - accuracy: 0.4932 - val_loss: 1.0748 - val_accuracy: 0.5233\n",
      "Epoch 7/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 1.1014 - accuracy: 0.5112 - val_loss: 1.0430 - val_accuracy: 0.5393\n",
      "Epoch 8/100\n",
      "109/109 [==============================] - 3s 27ms/step - loss: 1.0824 - accuracy: 0.5180 - val_loss: 1.0084 - val_accuracy: 0.5660\n",
      "Epoch 9/100\n",
      "109/109 [==============================] - 3s 27ms/step - loss: 1.0519 - accuracy: 0.5429 - val_loss: 0.9285 - val_accuracy: 0.6020\n",
      "Epoch 10/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 1.0416 - accuracy: 0.5423 - val_loss: 0.9156 - val_accuracy: 0.6080\n",
      "Epoch 11/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 1.0239 - accuracy: 0.5458 - val_loss: 0.9119 - val_accuracy: 0.5960\n",
      "Epoch 12/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.9889 - accuracy: 0.5584 - val_loss: 0.8462 - val_accuracy: 0.6307\n",
      "Epoch 13/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.9695 - accuracy: 0.5780 - val_loss: 0.7973 - val_accuracy: 0.6620\n",
      "Epoch 14/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.9592 - accuracy: 0.5829 - val_loss: 0.8211 - val_accuracy: 0.6367\n",
      "Epoch 15/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.9544 - accuracy: 0.5875 - val_loss: 0.8816 - val_accuracy: 0.6173\n",
      "Epoch 16/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.9338 - accuracy: 0.5998 - val_loss: 0.7915 - val_accuracy: 0.6647\n",
      "Epoch 17/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.9270 - accuracy: 0.6055 - val_loss: 0.8044 - val_accuracy: 0.6560\n",
      "Epoch 18/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.9065 - accuracy: 0.6016 - val_loss: 0.7396 - val_accuracy: 0.6840\n",
      "Epoch 19/100\n",
      "109/109 [==============================] - 3s 27ms/step - loss: 0.9062 - accuracy: 0.6058 - val_loss: 0.7133 - val_accuracy: 0.7067\n",
      "Epoch 20/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.8740 - accuracy: 0.6324 - val_loss: 0.6863 - val_accuracy: 0.7280\n",
      "Epoch 21/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.8751 - accuracy: 0.6193 - val_loss: 0.7313 - val_accuracy: 0.7020\n",
      "Epoch 22/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.8546 - accuracy: 0.6365 - val_loss: 0.7864 - val_accuracy: 0.6753\n",
      "Epoch 23/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.8455 - accuracy: 0.6484 - val_loss: 0.6526 - val_accuracy: 0.7507\n",
      "Epoch 24/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.8138 - accuracy: 0.6634 - val_loss: 0.6296 - val_accuracy: 0.7693\n",
      "Epoch 25/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.7903 - accuracy: 0.6836 - val_loss: 0.6489 - val_accuracy: 0.7660\n",
      "Epoch 26/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.8044 - accuracy: 0.6752 - val_loss: 0.5743 - val_accuracy: 0.7813\n",
      "Epoch 27/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.7653 - accuracy: 0.6878 - val_loss: 0.5894 - val_accuracy: 0.7793\n",
      "Epoch 28/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.7669 - accuracy: 0.7044 - val_loss: 0.5302 - val_accuracy: 0.8167\n",
      "Epoch 29/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.7770 - accuracy: 0.6903 - val_loss: 0.4874 - val_accuracy: 0.8447\n",
      "Epoch 30/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.7369 - accuracy: 0.7176 - val_loss: 0.4947 - val_accuracy: 0.8167\n",
      "Epoch 31/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.7105 - accuracy: 0.7297 - val_loss: 0.4711 - val_accuracy: 0.8387\n",
      "Epoch 32/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.7063 - accuracy: 0.7321 - val_loss: 0.4579 - val_accuracy: 0.8500\n",
      "Epoch 33/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.6852 - accuracy: 0.7442 - val_loss: 0.5023 - val_accuracy: 0.8267\n",
      "Epoch 34/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.6951 - accuracy: 0.7396 - val_loss: 0.4737 - val_accuracy: 0.8387\n",
      "Epoch 35/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.6822 - accuracy: 0.7454 - val_loss: 0.4208 - val_accuracy: 0.8547\n",
      "Epoch 36/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.6651 - accuracy: 0.7524 - val_loss: 0.3899 - val_accuracy: 0.8747\n",
      "Epoch 37/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.6761 - accuracy: 0.7500 - val_loss: 0.3869 - val_accuracy: 0.8793\n",
      "Epoch 38/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.6456 - accuracy: 0.7696 - val_loss: 0.3680 - val_accuracy: 0.8813\n",
      "Epoch 39/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.6435 - accuracy: 0.7643 - val_loss: 0.3456 - val_accuracy: 0.8960\n",
      "Epoch 40/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.6140 - accuracy: 0.7710 - val_loss: 0.3681 - val_accuracy: 0.8840\n",
      "Epoch 41/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.6041 - accuracy: 0.7762 - val_loss: 0.3846 - val_accuracy: 0.8800\n",
      "Epoch 42/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.5992 - accuracy: 0.7837 - val_loss: 0.3769 - val_accuracy: 0.8793\n",
      "Epoch 43/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.6062 - accuracy: 0.7841 - val_loss: 0.3047 - val_accuracy: 0.9067\n",
      "Epoch 44/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.5956 - accuracy: 0.7811 - val_loss: 0.3482 - val_accuracy: 0.8847\n",
      "Epoch 45/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.6260 - accuracy: 0.7677 - val_loss: 0.3457 - val_accuracy: 0.8813\n",
      "Epoch 46/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.5664 - accuracy: 0.7966 - val_loss: 0.3211 - val_accuracy: 0.8940\n",
      "Epoch 47/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.5776 - accuracy: 0.7923 - val_loss: 0.2992 - val_accuracy: 0.9113\n",
      "Epoch 48/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.5703 - accuracy: 0.7955 - val_loss: 0.2883 - val_accuracy: 0.9113\n",
      "Epoch 49/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.5568 - accuracy: 0.8038 - val_loss: 0.2696 - val_accuracy: 0.9127\n",
      "Epoch 50/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.5474 - accuracy: 0.8027 - val_loss: 0.2894 - val_accuracy: 0.9160\n",
      "Epoch 51/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.5714 - accuracy: 0.7925 - val_loss: 0.2618 - val_accuracy: 0.9193\n",
      "Epoch 52/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.5353 - accuracy: 0.7989 - val_loss: 0.2757 - val_accuracy: 0.9173\n",
      "Epoch 53/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.5343 - accuracy: 0.8172 - val_loss: 0.2389 - val_accuracy: 0.9300\n",
      "Epoch 54/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.5451 - accuracy: 0.8110 - val_loss: 0.2399 - val_accuracy: 0.9253\n",
      "Epoch 55/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.5234 - accuracy: 0.8115 - val_loss: 0.2463 - val_accuracy: 0.9260\n",
      "Epoch 56/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4963 - accuracy: 0.8269 - val_loss: 0.2564 - val_accuracy: 0.9220\n",
      "Epoch 57/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.5138 - accuracy: 0.8151 - val_loss: 0.2353 - val_accuracy: 0.9273\n",
      "Epoch 58/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.5256 - accuracy: 0.8124 - val_loss: 0.2349 - val_accuracy: 0.9273\n",
      "Epoch 59/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.5106 - accuracy: 0.8213 - val_loss: 0.2491 - val_accuracy: 0.9220\n",
      "Epoch 60/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.5221 - accuracy: 0.8139 - val_loss: 0.2245 - val_accuracy: 0.9347\n",
      "Epoch 61/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4990 - accuracy: 0.8199 - val_loss: 0.2317 - val_accuracy: 0.9287\n",
      "Epoch 62/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.4738 - accuracy: 0.8304 - val_loss: 0.2104 - val_accuracy: 0.9380\n",
      "Epoch 63/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4964 - accuracy: 0.8190 - val_loss: 0.2169 - val_accuracy: 0.9360\n",
      "Epoch 64/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4998 - accuracy: 0.8182 - val_loss: 0.1960 - val_accuracy: 0.9400\n",
      "Epoch 65/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4951 - accuracy: 0.8217 - val_loss: 0.2240 - val_accuracy: 0.9387\n",
      "Epoch 66/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.4793 - accuracy: 0.8291 - val_loss: 0.1853 - val_accuracy: 0.9420\n",
      "Epoch 67/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4569 - accuracy: 0.8406 - val_loss: 0.1791 - val_accuracy: 0.9433\n",
      "Epoch 68/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4713 - accuracy: 0.8347 - val_loss: 0.1925 - val_accuracy: 0.9420\n",
      "Epoch 69/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.4712 - accuracy: 0.8355 - val_loss: 0.1908 - val_accuracy: 0.9400\n",
      "Epoch 70/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4753 - accuracy: 0.8372 - val_loss: 0.1994 - val_accuracy: 0.9353\n",
      "Epoch 71/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.4663 - accuracy: 0.8328 - val_loss: 0.1955 - val_accuracy: 0.9387\n",
      "Epoch 72/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4555 - accuracy: 0.8374 - val_loss: 0.1845 - val_accuracy: 0.9447\n",
      "Epoch 73/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.4554 - accuracy: 0.8459 - val_loss: 0.1841 - val_accuracy: 0.9433\n",
      "Epoch 74/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.4590 - accuracy: 0.8411 - val_loss: 0.1647 - val_accuracy: 0.9487\n",
      "Epoch 75/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4470 - accuracy: 0.8395 - val_loss: 0.2000 - val_accuracy: 0.9380\n",
      "Epoch 76/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4288 - accuracy: 0.8449 - val_loss: 0.1928 - val_accuracy: 0.9413\n",
      "Epoch 77/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.4467 - accuracy: 0.8393 - val_loss: 0.1591 - val_accuracy: 0.9513\n",
      "Epoch 78/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4505 - accuracy: 0.8364 - val_loss: 0.1755 - val_accuracy: 0.9427\n",
      "Epoch 79/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.4426 - accuracy: 0.8464 - val_loss: 0.1415 - val_accuracy: 0.9600\n",
      "Epoch 80/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.4234 - accuracy: 0.8561 - val_loss: 0.1799 - val_accuracy: 0.9467\n",
      "Epoch 81/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4265 - accuracy: 0.8486 - val_loss: 0.1528 - val_accuracy: 0.9513\n",
      "Epoch 82/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4336 - accuracy: 0.8472 - val_loss: 0.1481 - val_accuracy: 0.9520\n",
      "Epoch 83/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4165 - accuracy: 0.8553 - val_loss: 0.1363 - val_accuracy: 0.9640\n",
      "Epoch 84/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4062 - accuracy: 0.8549 - val_loss: 0.1492 - val_accuracy: 0.9593\n",
      "Epoch 85/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4016 - accuracy: 0.8616 - val_loss: 0.1506 - val_accuracy: 0.9587\n",
      "Epoch 86/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.4400 - accuracy: 0.8441 - val_loss: 0.1557 - val_accuracy: 0.9540\n",
      "Epoch 87/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.3948 - accuracy: 0.8633 - val_loss: 0.1301 - val_accuracy: 0.9627\n",
      "Epoch 88/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.3966 - accuracy: 0.8573 - val_loss: 0.1291 - val_accuracy: 0.9587\n",
      "Epoch 89/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.3915 - accuracy: 0.8527 - val_loss: 0.1452 - val_accuracy: 0.9600\n",
      "Epoch 90/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4239 - accuracy: 0.8531 - val_loss: 0.1291 - val_accuracy: 0.9573\n",
      "Epoch 91/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.4006 - accuracy: 0.8572 - val_loss: 0.1300 - val_accuracy: 0.9613\n",
      "Epoch 92/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.3858 - accuracy: 0.8629 - val_loss: 0.1164 - val_accuracy: 0.9673\n",
      "Epoch 93/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.4030 - accuracy: 0.8577 - val_loss: 0.1413 - val_accuracy: 0.9547\n",
      "Epoch 94/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.3865 - accuracy: 0.8619 - val_loss: 0.1208 - val_accuracy: 0.9653\n",
      "Epoch 95/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.3832 - accuracy: 0.8621 - val_loss: 0.1379 - val_accuracy: 0.9607\n",
      "Epoch 96/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4130 - accuracy: 0.8514 - val_loss: 0.1352 - val_accuracy: 0.9593\n",
      "Epoch 97/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.3887 - accuracy: 0.8676 - val_loss: 0.1156 - val_accuracy: 0.9633\n",
      "Epoch 98/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.3849 - accuracy: 0.8622 - val_loss: 0.1159 - val_accuracy: 0.9667\n",
      "Epoch 99/100\n",
      "109/109 [==============================] - 3s 25ms/step - loss: 0.3698 - accuracy: 0.8628 - val_loss: 0.1200 - val_accuracy: 0.9633\n",
      "Epoch 100/100\n",
      "109/109 [==============================] - 3s 24ms/step - loss: 0.4019 - accuracy: 0.8559 - val_loss: 0.1221 - val_accuracy: 0.9620\n"
     ]
    }
   ],
   "source": [
    "# Model parameters\n",
    "dropout = 0.5\n",
    "learning_rate = 1e-3\n",
    "epochs = 100\n",
    "\n",
    "#Building the model\n",
    "\n",
    "cnn_lstm_model = Sequential()\n",
    "\n",
    "# First block of conv.\n",
    "cnn_lstm_model.add(Conv2D(filters=25, kernel_size=(10,1), padding='same', activation='elu', input_shape=(250,1,22)))\n",
    "cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "cnn_lstm_model.add(BatchNormalization())\n",
    "cnn_lstm_model.add(Dropout(dropout))\n",
    "\n",
    "# Second block of conv.\n",
    "cnn_lstm_model.add(Conv2D(filters=50, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "cnn_lstm_model.add(BatchNormalization())\n",
    "cnn_lstm_model.add(Dropout(dropout))\n",
    "\n",
    "# Third block of conv.\n",
    "cnn_lstm_model.add(Conv2D(filters=100, kernel_size=(10,1), padding='same', activation='elu'))\n",
    "cnn_lstm_model.add(MaxPooling2D(pool_size=(3,1), padding='same'))\n",
    "cnn_lstm_model.add(BatchNormalization())\n",
    "cnn_lstm_model.add(Dropout(dropout))\n",
    "\n",
    "# FC+LSTM layer\n",
    "cnn_lstm_model.add(Flatten())\n",
    "cnn_lstm_model.add(Dense((50)))\n",
    "cnn_lstm_model.add(Reshape((50,1)))\n",
    "cnn_lstm_model.add(LSTM(10, dropout=0.5, recurrent_dropout=0.5, input_shape=(50,1), return_sequences=False))\n",
    "\n",
    "# FC layer\n",
    "cnn_lstm_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Defining the optimizer\n",
    "optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
    "\n",
    "# Compiling the model\n",
    "cnn_lstm_model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer=optimizer,\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "# Printing the model summary\n",
    "cnn_lstm_model.summary()\n",
    "\n",
    "# Training and validating the model\n",
    "\n",
    "cnn_lstm_results = cnn_lstm_model.fit(x_train,\n",
    "             y_train,\n",
    "             batch_size=64,\n",
    "             epochs=epochs,\n",
    "             validation_data=(x_valid, y_valid), verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *\n        return step_function(self, iterator)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1185 test_step\n        self.compiled_loss(\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1537 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:4833 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 16, 4) and (None, 4) are incompatible\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7715daf08534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Testing the CNN-LSTM model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_lstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy of the CNN-LSTM model:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m~/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3355\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3357\u001b[0;31m             return self._define_function_with_shape_relaxation(\n\u001b[0m\u001b[1;32m   3358\u001b[0m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3277\u001b[0m           expand_composites=True)\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3279\u001b[0;31m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[1;32m   3280\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1233 test_function  *\n        return step_function(self, iterator)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1224 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1217 run_step  **\n        outputs = model.test_step(data)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1185 test_step\n        self.compiled_loss(\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/compile_utils.py:203 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:152 __call__\n        losses = call_fn(y_true, y_pred)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:256 call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/losses.py:1537 categorical_crossentropy\n        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/keras/backend.py:4833 categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n    /home/dy/Desktop/c247_project/.venv/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with\n        raise ValueError(\"Shapes %s and %s are incompatible\" % (self, other))\n\n    ValueError: Shapes (None, 16, 4) and (None, 4) are incompatible\n"
     ]
    }
   ],
   "source": [
    "## Testing the CNN-LSTM model\n",
    "\n",
    "score = cnn_lstm_model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test accuracy of the CNN-LSTM model:',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}